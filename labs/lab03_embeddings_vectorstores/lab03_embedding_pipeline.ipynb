{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3219006",
   "metadata": {},
   "source": [
    "# Lab 03 — Building the Embedding & Vector Database Pipeline\n",
    "\n",
    "**Course:** A Practical Guide to Building a GenAI Application\n",
    "\n",
    "**Duration:** 90–120 minutes\n",
    "\n",
    "**Objectives:**\n",
    "- Understand embeddings & vector search\n",
    "- Build a complete text‑to‑embedding pipeline\n",
    "- Implement chunking, cleaning, embedding, and storage\n",
    "- Use a real vector database (FAISS for this lab)\n",
    "- Evaluate similarity search accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb70399a",
   "metadata": {},
   "source": [
    "## 1 — Introduction to Embeddings\n",
    "\n",
    "Embeddings convert text into numerical vectors representing semantic meaning.\n",
    "\n",
    "Examples of embedding models:\n",
    "- OpenAI text-embedding-3-large\n",
    "- BGE Large / Small\n",
    "- Sentence Transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55730b8d",
   "metadata": {},
   "source": [
    "## 2 — Install dependencies\n",
    "\n",
    "Run this cell to install required libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d078247",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-cpu sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb39c9b6",
   "metadata": {},
   "source": [
    "## 3 — Load an embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982d780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361bbc63",
   "metadata": {},
   "source": [
    "## 4 — Create a sample document set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4b9cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    'The Nigerian Stock Exchange closed higher today.',\n",
    "    'The Central Bank of Nigeria announced new monetary policies.',\n",
    "    'Python is a popular programming language for AI.',\n",
    "    'Lagos is the commercial capital of Nigeria.'\n",
    "]\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35b4082",
   "metadata": {},
   "source": [
    "## 5 — Chunking & Text Cleaning\n",
    "\n",
    "### Exercise: Implement a simple chunking function.\n",
    "Chunk size = 40 words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85cf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean(text):\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def chunk(text, size=40):\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i+size]) for i in range(0, len(words), size)]\n",
    "\n",
    "chunks = []\n",
    "for doc in documents:\n",
    "    cleaned = clean(doc)\n",
    "    chunks.extend(chunk(cleaned))\n",
    "\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e31548",
   "metadata": {},
   "source": [
    "## 6 — Convert chunks to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af66f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(chunks, convert_to_numpy=True)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b013d23",
   "metadata": {},
   "source": [
    "## 7 — Build a Vector Database (FAISS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede9b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "d = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(embeddings)\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a7a123",
   "metadata": {},
   "source": [
    "## 8 — Perform Similarity Search\n",
    "\n",
    "Query example: *What is the role of the Central Bank of Nigeria?*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debd83c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What does the Central Bank of Nigeria do?'\n",
    "query_vec = model.encode([query])\n",
    "D, I = index.search(query_vec, k=2)\n",
    "I, D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78812772",
   "metadata": {},
   "source": [
    "### Return matching chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba873ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "[chunks[i] for i in I[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d371181",
   "metadata": {},
   "source": [
    "## 9 — Lab Exercise: Improve Retrieval Quality\n",
    "\n",
    "### Task:\n",
    "- Add your own 5 documents\n",
    "- Rebuild embeddings\n",
    "- Run 3 queries\n",
    "- Compare FAISS results and explain which are correct or incorrect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81403b6b",
   "metadata": {},
   "source": [
    "## 10 — Instructor Key\n",
    "\n",
    "**Expected improvements:**\n",
    "- More diverse documents increase accuracy\n",
    "- Longer chunks reduce context fragmentation\n",
    "- Using a larger embedding model improves semantic recall\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
