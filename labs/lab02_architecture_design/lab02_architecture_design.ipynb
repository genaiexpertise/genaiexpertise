{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f495104f",
   "metadata": {},
   "source": [
    "# Lab 02 — GenAI Application Architecture Design\n",
    "\n",
    "**Course:** A Practical Guide to Building a GenAI Application\n",
    "\n",
    "**Duration:** 90–120 minutes\n",
    "\n",
    "**Objectives:**\n",
    "- Understand the components of a production GenAI application\n",
    "- Design a modular, scalable architecture\n",
    "- Learn patterns for RAG systems, agents, and hybrid architectures\n",
    "- Create sequence diagrams, architecture blocks, and data flows\n",
    "- Complete hands-on architecture design exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f98d2d",
   "metadata": {},
   "source": [
    "## 1 — Why Architecture Matters in GenAI\n",
    "\n",
    "A good GenAI architecture ensures:\n",
    "\n",
    "- Scalability\n",
    "- Modular development\n",
    "- Lower latency\n",
    "- Cheaper inference\n",
    "- Separation of concerns\n",
    "- Easier debugging and logging\n",
    "- Better retrieval accuracy (in RAG apps)\n",
    "\n",
    "Your GenAI app is only as good as its architecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824a6727",
   "metadata": {},
   "source": [
    "## 2 — Core Components\n",
    "\n",
    "Below is the standard architecture breakdown (high level):\n",
    "\n",
    "```\n",
    "┌──────────────────────────────┐\n",
    "│          Frontend            │\n",
    "│  (Next.js, React, Flutter)   │\n",
    "└───────────────┬──────────────┘\n",
    "                │\n",
    "┌───────────────▼──────────────┐\n",
    "│           Backend API         │\n",
    "│         (FastAPI, Flask)      │\n",
    "└───────────────┬──────────────┘\n",
    "                │\n",
    "       ┌────────▼────────┐\n",
    "       │  LLM Orchestration │\n",
    "       │ (LangChain, LlamaIndex) │\n",
    "       └─────────┬────────┘\n",
    "                 │\n",
    "     ┌───────────▼───────────┐\n",
    "     │   Knowledge Layer      │\n",
    "     │ (Vector DB, Document   │\n",
    "     │  loaders, chunking)    │\n",
    "     └───────────┬───────────┘\n",
    "                 │\n",
    "      ┌──────────▼──────────┐\n",
    "      │     Storage Layer    │\n",
    "      │ (Postgres, S3, Logs) │\n",
    "      └──────────────────────┘\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed85eb",
   "metadata": {},
   "source": [
    "### Brief descriptions\n",
    "\n",
    "- **Frontend:** Chat UI, document upload, streaming.\n",
    "- **Backend API:** Ingestion, query endpoints, auth, telemetry.\n",
    "- **Orchestration:** Chains, agents, reranking logic.\n",
    "- **Knowledge layer:** Chunking, embeddings, vector DB.\n",
    "- **Storage:** Long-term storage for documents, logs and metadata.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f84c75",
   "metadata": {},
   "source": [
    "## 3 — RAG Architecture (Standard Flow)\n",
    "\n",
    "```\n",
    "User Question\n",
    "      │\n",
    "      ▼\n",
    "┌─────────────┐\n",
    "│  Backend    │\n",
    "│  (FastAPI)  │\n",
    "└──────┬──────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────┐\n",
    "│ Query Router│\n",
    "│ + Rewriter  │\n",
    "└──────┬──────┘\n",
    "       │\n",
    "       ▼\n",
    "┌─────────────┐\n",
    "│ Vector Store│\n",
    "│ Retrieval   │\n",
    "└──────┬──────┘\n",
    "       │\n",
    "       ▼\n",
    "┌───────────────┐\n",
    "│Reranker (opt.) │\n",
    "└──────┬────────┘\n",
    "       │\n",
    "       ▼\n",
    "┌───────────────────────┐\n",
    "│LLM: Answer Generation  │\n",
    "└────────────────────────┘\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73507b00",
   "metadata": {},
   "source": [
    "## 4 — Sequence Diagram for a Query\n",
    "\n",
    "```\n",
    "User → Frontend: submit question\n",
    "Frontend → Backend: POST /query\n",
    "Backend → Orchestrator: prepare_query()\n",
    "Orchestrator → VectorDB: similarity_search()\n",
    "VectorDB → Orchestrator: return chunks\n",
    "Orchestrator → LLM: generate answer with context\n",
    "LLM → Orchestrator: answer\n",
    "Orchestrator → Backend: result\n",
    "Backend → Frontend: stream answer to user\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e8e97b",
   "metadata": {},
   "source": [
    "## 5 — Lab Exercise 1: Draw Your Own Architecture\n",
    "\n",
    "**Task:** Design an architecture for a GenAI application that:\n",
    "- Accepts PDF uploads\n",
    "- Performs chunking\n",
    "- Stores embeddings\n",
    "- Answers user questions\n",
    "- Tracks feedback\n",
    "\n",
    "**Deliverable:** Use ASCII, pen & paper, or draw.io. Paste your ASCII diagram into the cell below.\n",
    "\n",
    "**Hint:** Start with Frontend → Backend → Ingestion → Vector DB → Orchestrator → LLM → Frontend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f06c30bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frontend -> Backend (FastAPI)\n",
      "  Backend -> Ingestion Service (extract, chunk, embed)\n",
      "  Ingestion -> VectorDB (Weaviate)\n",
      "  User Query -> Backend -> Orchestrator -> VectorDB -> Reranker -> LLM -> Backend -> Frontend\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Paste your ASCII diagram as a triple-quoted string here\n",
    "my_diagram = '''\n",
    "Frontend -> Backend (FastAPI)\n",
    "  Backend -> Ingestion Service (extract, chunk, embed)\n",
    "  Ingestion -> VectorDB (Weaviate)\n",
    "  User Query -> Backend -> Orchestrator -> VectorDB -> Reranker -> LLM -> Backend -> Frontend\n",
    "'''\n",
    "print(my_diagram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5139ee",
   "metadata": {},
   "source": [
    "## 6 — Lab Exercise 2: Identify Bottlenecks\n",
    "\n",
    "Given this flawed architecture:\n",
    "\n",
    "```\n",
    "User → Backend → OpenAI → Pinecone → Backend → User\n",
    "```\n",
    "\n",
    "**Questions:**\n",
    "1. What are the missing steps?\n",
    "2. What risks exist?\n",
    "3. What component should be added?\n",
    "4. How do you improve latency?\n",
    "\n",
    "Write your answers in the code cell below as a Python dict (for easy grading).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0886ddaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'missing_steps': ['chunking',\n",
       "  'embeddings',\n",
       "  'retrieval',\n",
       "  'context_building',\n",
       "  'reranking'],\n",
       " 'risks': ['hallucination',\n",
       "  'no_source_grounding',\n",
       "  'slow_performance',\n",
       "  'higher_costs'],\n",
       " 'components_to_add': ['chunker',\n",
       "  'embedding_service',\n",
       "  'vector_db',\n",
       "  'reranker',\n",
       "  'orchestrator'],\n",
       " 'latency_improvements': ['caching',\n",
       "  'smaller_models',\n",
       "  'batching',\n",
       "  'pre-warm',\n",
       "  'reduce_context_size']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_ex2 = {\n",
    "    'missing_steps': ['chunking', 'embeddings', 'retrieval', 'context_building', 'reranking'],\n",
    "    'risks': ['hallucination','no_source_grounding','slow_performance','higher_costs'],\n",
    "    'components_to_add': ['chunker','embedding_service','vector_db','reranker','orchestrator'],\n",
    "    'latency_improvements': ['caching','smaller_models','batching','pre-warm','reduce_context_size']\n",
    "}\n",
    "answers_ex2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f21323f",
   "metadata": {},
   "source": [
    "## 7 — Lab Exercise 3: Build Architecture From Requirements (NaijaLawBot)\n",
    "\n",
    "**Scenario:** NaijaLawBot must:\n",
    "- Accept Nigerian laws (PDF/DOCX)\n",
    "- Extract text and chunk\n",
    "- Store embeddings in vector DB\n",
    "- LLM must cite sources\n",
    "- Frontend shows highlighted source text\n",
    "- Support offline local Llama models with fallback\n",
    "- Admin dashboard (ingestion logs, usage, hallucination reports)\n",
    "\n",
    "**Task:** Describe the full system architecture. Paste a free-text description + ASCII diagram in the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cd1c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "naijalawbot_arch = '''\n",
    "User -> Frontend (Next.js)\n",
    "Frontend -> API Gateway (FastAPI)\n",
    "API -> Ingestion Service: (PDF/DOCX -> text extraction -> clean -> chunk)\n",
    "Chunks -> Embedding Service (OpenAI or local SBERT)\n",
    "Embeddings -> VectorDB (Weaviate) + Metadata in Postgres\n",
    "Query Path: User Query -> Query Router -> Retriever (hybrid) -> Reranker -> LLM (OpenAI primary, Local Llama fallback)\n",
    "LLM -> Citation Generator -> Response Builder -> Frontend (highlights + links to source chunks)\n",
    "Admin: Logs -> Postgres / ELK, Monitoring -> Prometheus+Grafana, Dashboard -> Admin UI\n",
    "'''\n",
    "print(naijalawbot_arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f527c9",
   "metadata": {},
   "source": [
    "## 8 — Bonus: Multi-Agent Architecture\n",
    "\n",
    "**Design an agent workflow for market research report generation.**\n",
    "\n",
    "Example flow:\n",
    "```\n",
    "User Query → Controller Agent → Research Agent → Summarizer Agent → Compliance Agent → Finalizer Agent → User\n",
    "```\n",
    "\n",
    "Describe responsibilities of each agent in the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ddfcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = {\n",
    "    'Controller': 'Orchestrates agents, splits tasks, aggregates outputs',\n",
    "    'Research': 'Fetches documents, queries vector DB, external web research',\n",
    "    'Summarizer': 'Condenses findings into structured sections',\n",
    "    'Compliance': 'Ensures regulatory and ethical checks, flags risky claims',\n",
    "    'Finalizer': 'Formats report, creates citations, polish language'\n",
    "}\n",
    "agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a16a61c",
   "metadata": {},
   "source": [
    "## 9 — Instructor Answers (Model Key)\n",
    "\n",
    "Answers are provided below for instructors and self-checking. Students should attempt all exercises before reading.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ecb40d",
   "metadata": {},
   "source": [
    "### Exercise 1 — Example Architecture\n",
    "\n",
    "```\n",
    "Frontend (Next.js)\n",
    "    ↓\n",
    "Backend API (FastAPI)\n",
    "    ↓\n",
    "Document Processor\n",
    "    - Text extractor\n",
    "    - Chunker\n",
    "    - Embeddings\n",
    "    ↓\n",
    "Vector DB (Weaviate or Pinecone)\n",
    "    ↓\n",
    "RAG Orchestrator (LangChain)\n",
    "    ↓\n",
    "LLM (OpenAI or Local Ollama)\n",
    "    ↓\n",
    "Feedback Store (Postgres)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc135f4",
   "metadata": {},
   "source": [
    "### Exercise 2 — Bottlenecks & Fixes\n",
    "\n",
    "**Missing steps:** chunking, embeddings, retrieval, reranking, context building.\n",
    "\n",
    "**Risks:** hallucinations, no source grounding, incorrect answers, slow performance.\n",
    "\n",
    "**Add components:** chunker, embedding service, vector DB, reranker, orchestrator.\n",
    "\n",
    "**Latency improvements:** caching, using smaller/faster models, batching, pre-warming, reducing context size, async processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf6715b",
   "metadata": {},
   "source": [
    "### Exercise 3 — NaijaLawBot (Suggested Architecture)\n",
    "\n",
    "```\n",
    "User (Web/Mobile)\n",
    "   ↓\n",
    "Frontend (Next.js)\n",
    "   ↓\n",
    "API Gateway / FastAPI\n",
    "   ↓\n",
    "Ingestion Service\n",
    "   ↓  (PDF, DOCX)\n",
    "Text Extraction\n",
    "   ↓\n",
    "Semantic Chunking\n",
    "   ↓\n",
    "Embeddings (OpenAI or Local)\n",
    "   ↓\n",
    "Vector DB (Weaviate)\n",
    "———————— Query Path ——————————\n",
    "User Query → Query Router → Retriever (Hybrid) → Reranker → LLM (OpenAI + Local fallback) → Citation Generator → Response Builder → Frontend\n",
    "———————— Admin Tools ——————————\n",
    "Logs → PostgreSQL\n",
    "Monitoring → Prometheus/Grafana\n",
    "Dashboard → Admin Panel\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb491cff",
   "metadata": {},
   "source": [
    "## 10 — Next Steps & Resources\n",
    "\n",
    "- Convert this ASCII diagram to a visual diagram (draw.io, Miro)\n",
    "- Implement a minimal FastAPI + vector DB integration (Lab 05 & Lab 03)\n",
    "- Read: LangChain/RAG docs, Weaviate guides, LlamaIndex examples\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
